---
title: "Choose Your Own Project: Wine Quality"
subtitle: "HarvardX PH125.9x Data Science: Capstone"
author: "Shunsuke Kobayashi"
date: "final: `r Sys.Date()`"
output:
  pdf_document:
    toc: TRUE
    toc_depth: 3
    number_sections: TRUE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, echo = TRUE)
knitr::opts_chunk$set(fig.width = 5, fig.height =3, fig.align = "center",
                      fig.pos = "h")
```
```{r, include=FALSE, echo=FALSE}
# Note: this process could take a couple of minutes
# (Sometimes it takes several tens of minutes)

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(knitr)) install.packages("knitr", repos = "http://cran.us.r-project.org")
# if(!require(doParallel)){install.packages("doParallel", repos = "http://cran.us.r-project.org")} 
if(!require(xgboost)){install.packages("xgboost", repos = "http://cran.us.r-project.org")} 
if(!require(patchwork)){install.packages("patchwork", repos = "http://cran.us.r-project.org")} 
if(!require(dslabs)){install.packages("dslabs", repos = "http://cran.us.r-project.org")}
if(!require(torch)){install.packages("torch", repos = "http://cran.us.r-project.org")}
if(!require(tabnet)){install.packages("tabnet", repos = "http://cran.us.r-project.org")}
if(!require(tidymodels)){install.packages("tidymodels", repos = "http://cran.us.r-project.org")}
if(!require(withr)){install.packages("withr", repos = "http://cran.us.r-project.org")}
if(!require(vip)){install.packages("vip", repos = "http://cran.us.r-project.org")}
if(!require(recipes)){install.packages("recipes", repos = "http://cran.us.r-project.org")}
if(!require(rpart)){install.packages("rpart", repos = "http://cran.us.r-project.org")}
if(!require(rattle)){install.packages("rattle", repos = "http://cran.us.r-project.org")}
if(!require(kernlab)){install.packages("kernlab", repos = "http://cran.us.r-project.org")}
if(!require(ggcorrplot)){install.packages("ggcorrplot", repos = "http://cran.us.r-project.org")}


```

```{r, include=FALSE, echo=FALSE}
# Loading all needed libraries

# library(doParallel) 
library(xgboost)
library(dslabs)
library(tidyverse)
library(caret)
library(knitr)
library(patchwork)
library(ggplot2)
library(data.table)
library(torch)
library(tabnet)
library(tidymodels)
library(withr)
library(recipes)
library(vip)
library(rpart)
library(rattle)
library(kernlab)
library(ggcorrplot)
```

```{r, include=FALSE, echo=FALSE}
# set the Parallel (to improve the speed)
# nc <- detectCores()
# cl <- makePSOCKcluster(nc)
# registerDoParallel(cl)
```
\newpage


# Introduction

The goal of this project is to use wine quality data sets for classification.

In the previous MovieLens project, we did machine learning using 10 million data, and we see this as an application problem in BtoC business such like Netflix, Amazon etc. In this CYO project, we set it up as a way to apply it to BtoB business, especially with small data sets in the field of product manufacturing and technology development. The red wine quality data set is a set of about 1,600 tabular tables, consisting of information such as alcohol and acid content, pH, and density, in addition to the target quality (This is similar to the structure of information in the chemical industry to which I belong).

In addition, the goal was to learn and compare not only learned methods but also newly algorithms developed and apply new technologies. In addition to the gradient boosting method, we also worked on the deep learning library **torch**, whose R version will be implemented in September 2020, and the classification in **Tabnet** that utilizes it, and created 10 models. In the new technology, we also worked on using the **GPU** with Google Colaboratory and succeeded in reducing the computation time from 53 minutes when using the CPU to 35 minutes when using the GPU.


# Data Preprocessing and Explanatory Data Analysis

In the UCI repository, there are two datasets related to the Portuguese wine Vinho Verde, red and white. Due to privacy and logistical issues, only physicochemical (input) and sensory (output) variables are available.

The red wine quality data set is a set of about 1,600 tabular tables, consisting of information such as alcohol and acid content, pH, and density, in addition to the target quality (This is similar to the structure of information in the chemical industry to which I belong).

A similar dataset is the Water portability dataset from Kaggle, but we chose this one because it requires sign-in for automatic download and the red wine dataset has less data.


## Initial Data Preprocessing

It was confirmed that the 1599 rows of data consisted of only numerical data and that there was no missing data.

```{r}
# Wine Quality Data Set
# https://archive.ics.uci.edu/ml/datasets/Wine+Quality
# https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv

url <- c("https://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv")
wine <- read_delim(url,delim = ";")

# modify the column name

colnames(wine) <- c("fixed_acidity", "volatile_acidity","citric_acid",
                    "residual_sugar","chlorides","free_sulfur_dioxide",
                    "total_sulfur_dioxide","density","pH",
                    "sulphates","alcohol","quality")

### Check the data -----

# whole the data

head(wine) 
wine %>% summary()
sum(is.na(wine))
```


## Explanatory Data Analysis (EDA)

The relationship between the quality data and each Attribution, which is the target for classification, was confirmed. The relationship with quality and the correlation between each were confirmed. It can be seen that while alcohol and volatile acidity are likely to have an effect on quality, residual sugar has a small relationship not only with quality but also with other Attributions.

```{r,fig.width = 8, fig.height =5}
# Target: quality

table(wine$quality) 

# Distribution of each value

wine %>% gather() %>% 
  ggplot(aes(value)) + 
  geom_histogram(col="black") +
  facet_wrap(~key, scales = "free")

# Check the relations between each attribute and quality (target)

wine  %>% reshape2::melt(.,"quality") %>% 
  ggplot(aes(value, quality)) + 
  geom_point() +
  geom_smooth(method = lm, col = "red", fill = "red") +
  facet_wrap(~variable, scales = "free")

# Check the correlation 
## Compute a matrix of correlation p-values

p.mat <- cor_pmat(wine)

# X means no significant coefficient

round(cor(wine),2) %>% 
ggcorrplot(., method = "circle",  hc.order = TRUE, type = "lower", p.mat = p.mat)

```


## Prepare the train / test data set

In order to build a model as a classification problem for quality, we divided the data. Since the number of data is small (1600), we decided to split the data 80:20.
In order to make it a classification problem, a binomial classification was made for quality, with 1 being above 6 and 0 being below 6.
In order to check the magnitude of the effect of each Attribution, the numbers were centered and standardized. The **recipe** library was used for the conversion. By using this library, it is easy to complete missing values and to make dummy variables for categorical variables (although we did not use this library, we commented it out in the code).


```{r}
### Data preparation: Split the data set ----
# Preparation test and train data set for model selection
# Due to the small amount of data, 20% was used as test data.

set.seed(1, sample.kind="Rounding")
test_index <- createDataPartition(y = wine$quality, times = 1, p = 0.2, list = FALSE)
train_set <- wine[-test_index,]
test_set <- wine[test_index,]

# To build each model, centralization and standardization are done with recipe.

rec_pre <- recipe(train_set, quality~.) %>% 
  step_center(all_numeric(),-quality) %>% # Centralization 
  step_scale(all_numeric(), -quality) %>%  # Standardization
  # step_knnimpute(all_predictors(),K=5)  # There is no NA
  # step_dummy(all_predictors(), -all_numeric()) # There is no categorical data
  prep()

# apply the recipe

train <- bake(rec_pre, new_data = train_set)
test <-  bake(rec_pre, new_data = test_set)

# check the data

head(train) 
head(test) 

# Transform "quality" into binary

train$quality[train$quality < 6] <- 0
test$quality[test$quality < 6] <- 0
train$quality[train$quality > 0] <- 1
test$quality[test$quality > 0] <- 1

train$quality <- as.factor(train$quality)
test$quality <- as.factor(test$quality)


# summary 

summary(train)
summary(test)

```


# Methods and Analysis

We made the following models for the classification problem. The evaluation was done by using Accuracy. Accuracy was calculated by comparing the predictions made by each model using the test data set with the actual quality. 

The importance of each item was extracted and graphed if it could be extracted. As mentioned in the introduction, the model is intended to be used in actual business, and it is important to understand how the target changes by changing the value of each item. 

$$Accuracy = \dfrac{TP + TN}{TP + TN + FP + FN}$$

$$where \space  TP = True\ positive;\  FP = False\ positive;\  TN = True\ negative;\  FN = False\ negative$$

In the analysis of each model using the library **caret**, we decided to use cross validation and made 10 divisions. Automatic parameter tuning was used for tuning.

```{r}

#################
# MODEL Analysis
#################

# set the Cross Validation for caret package

trControl = trainControl(method = "cv", number = 10)

```


## Logistic Regression

Logistic regression analysis is a type of "multivariate analysis" in which analysis is performed from multiple variables to predict qualitative probabilities.

$$p= \dfrac{1}{1+e^{-(a_1x_1 + a_2x_2+...+a_nx_x + b)}}$$

## CART (Classification and Regression Tree)

CART is a machine learning method that makes predictions based on "Yes or No" conditions for feature values. We selected it as one of the models because it is characterized by easy understanding and interpretation of learning results.


## Random Forest

Since the learning results are easy to understand and interpret, we choose Random Forest as one of the models and train it using multiple decision trees. Random forests are trained using multiple decision trees, which are generated by randomly selecting data from the original training data. Then, when actually evaluating the unknown data, the conclusions of the individual decision trees are combined into an overall conclusion by majority voting.

Decision trees are a very straightforward algorithm, but they are known to fail to generate the desired tree structure depending on the data, and are prone to overlearning. Random forests, on the other hand, have the advantage that the effect of overlearning is much smaller than that of decision trees because the correlation between individual decision trees is low.


## SVM (Support-vector machine)

SVM is a machine learning model that can be applied to problems such as classification and regression. It is a method of determining which hyperplane (or straight line in the case of 2D) separating two classes of data is the farthest from each data.
Compared to other methods, it has advantages such as being able to obtain a highly accurate model even with a small amount of data, easily maintaining discrimination accuracy even when the number of dimensions (number of features) increases, and making it easy to adjust parameters. On the other hand, the amount of computation increases rapidly when the amount of training data increases, and the principle is two-class classification, so it is difficult to apply to multi-class classification.


## Neural Net

A neural network is a model of how the human brain works and is applied to computers.
Deep learning is a method of applying neural networks, also known as deep neural networks.
The basic model structure of a neural network consists of an **input layer**, a **hidden layer**, and an **output layer**.


## Gradient Boosting

Gradient boosting is a machine learning method for tasks such as regression and classification that generates a predictive model in the form of an ensemble of weak prediction models (usually decision trees).

In addition to XGBoost's Linear and Tree, which were also used in the MovieLens project, modeling is also done using a method called DART. In gradient boosting, there was a problem that the gradient was generally applied to fit the data in the more extreme locations towards the end of the step. In order to prevent overlearning, MART (Multiple Additive Regression Trees) is improved by introducing the concept of Drop Out, which is called DART (Dropouts meet Multiple Additive Regression Trees).

## Deep Learning

Deep learning, or deep learning, is a machine learning method that uses a neural network that reproduces the mechanism of human neurons, and is characterized by the use of a multilayer neural network. Deep learning is a machine learning method that uses neural networks that replicate the mechanism of human neurons, and is characterized by the use of multi-layered neural networks. It is currently producing significant results in various fields such as image recognition, speech recognition, and translation.

It has been possible to use the library **keras** to build deep learning models in R for some time. However, it requires a **python** environment for installation and is not suitable for automatic installation of projects.
The library **torch** has been implemented in R version in September 2020. In this project, we used torch to build a model for deep learning. 

We also worked on building a model with tabnet, which is available by installing torch; it is a deep learning for data tables announced by Google Cloud in 2020. Unlike deep learning, which works like a black box, in the case of TabNet the model can interpret the features it chooses.

# Results

## Each model

### logit

```{r}
# logistic ------

set.seed(1, sample.kind="Rounding")

# train the model

wine_logit <- train(
  quality ~ .,
  data = train,
  method = "glm",
  family = binomial(),
  trControl = trControl
)

# Check the model

summary(wine_logit)
p_logit <- varImp(wine_logit,scale = F) %>% 
  ggplot() + ggtitle("Logit")
p_logit

# Evaluate

confusionMatrix(predict(wine_logit, test), test$quality)
logit_acc <- confusionMatrix(predict(wine_logit, test), test$quality)$overall["Accuracy"]
logit_acc
```


### rpart

```{r}
### Rpart -------

set.seed(1, sample.kind="Rounding")

# train the model

wine_rpart <- train(
  quality ~ .,
  data = train,
  method = "rpart",
  trControl = trControl,
  tuneLength = 10
)

# Check the model

wine_rpart
fancyRpartPlot(wine_rpart$finalModel)
p_rpart <- varImp(wine_rpart,scale = F) %>% 
  ggplot() + ggtitle("Rpart")
p_rpart


# Evaluate

confusionMatrix(predict(wine_rpart, test), test$quality)
rpart_acc <- confusionMatrix(predict(wine_rpart, test), test$quality)$overall["Accuracy"]
rpart_acc

```


### rf

```{r}
### Random forest ------

set.seed(1, sample.kind="Rounding")

# train the model

wine_rf <- train(
  quality ~ .,
  data = train,
  method = "rf",
  trControl = trControl,
  tuneLength = 10
)

# Check the model

wine_rf
ggplot(wine_rf)
p_rf <- varImp(wine_rf,scale = F) %>% 
  ggplot() + ggtitle("RF")
p_rf


# Evaluate

confusionMatrix(predict(wine_rf, test), test$quality)
rf_acc <- confusionMatrix(predict(wine_rf, test), test$quality)$overall["Accuracy"]
rf_acc

```


### svm

```{r}
### SVM ------


set.seed(1, sample.kind="Rounding")

# train the model

wine_svm <- train(
  quality ~ .,
  data = train,
  method = "svmRadial",
  trControl = trControl,
  tuneLength = 10
)

# Check the model

wine_svm
ggplot(wine_svm)


# Evaluate

confusionMatrix(predict(wine_svm, test), test$quality)
svm_acc <- confusionMatrix(predict(wine_svm, test), test$quality)$overall["Accuracy"]
svm_acc

```


### nnet

```{r}
### Neural Net ------

set.seed(1, sample.kind="Rounding")

# train the model

wine_nnet <- train(
  quality ~ .,
  data = train,
  method = "nnet",
  trControl = trControl,
  tuneLength = 10,
  trace = FALSE
)

# Check the model

wine_nnet
ggplot(wine_nnet)
p_nnet <- varImp(wine_nnet,scale = F) %>% 
  ggplot() + ggtitle("NNet")
p_nnet


# Evaluate

confusionMatrix(predict(wine_nnet, test), test$quality)
nnet_acc <- confusionMatrix(predict(wine_nnet, test), test$quality)$overall["Accuracy"]
nnet_acc

```


### xgbLinear

```{r, results='hide'}
### XGBoost: xgbLinear----

set.seed(1, sample.kind="Rounding")

# train the model

wine_xgbl <- train(
  quality ~ .,
  data = train,
  method = "xgbLinear",
  trControl = trControl,
  tuneLength = 5
)

```

```{r}

# Check the model

wine_xgbl
ggplot(wine_xgbl)
p_xgbl <- varImp(wine_xgbl,scale = F) %>% 
  ggplot() + ggtitle("XGB L")
p_xgbl


# Evaluate

confusionMatrix(predict(wine_xgbl, test), test$quality)
xgbl_acc <- confusionMatrix(predict(wine_xgbl, test), test$quality)$overall["Accuracy"]
xgbl_acc

```


### xgbDART


```{r, results='hide'}
### XGBoost: xgbDART----

set.seed(1, sample.kind="Rounding")

# train the model

wine_xgbd <- train(
  quality ~ .,
  data = train,
  method = "xgbDART",
  trControl = trControl,
  tuneLength = 3
)



```
```{r}
# Check the model

wine_xgbd
p_xgbd <- varImp(wine_xgbd,scale = F) %>% 
  ggplot() + ggtitle("XGB D")
p_xgbd


# Evaluate

confusionMatrix(predict(wine_xgbd, test), test$quality)
xgbd_acc <- confusionMatrix(predict(wine_xgbd, test), test$quality)$overall["Accuracy"]
xgbd_acc
```


### xgbTree

```{r, results='hide'}
### XGBoost: xgbTree----

set.seed(1, sample.kind="Rounding")

# train the model

wine_xgbt <- train(
  quality ~ .,
  data = train,
  method = "xgbTree",
  trControl = trControl,
  tuneLength = 5
)



```
```{r}
# Check the model

wine_xgbt
p_xgbt <- varImp(wine_xgbt,scale = F) %>% 
  ggplot() + ggtitle("XGB T")
p_xgbt


# Evaluate

confusionMatrix(predict(wine_xgbt, test), test$quality)
xgbt_acc <- confusionMatrix(predict(wine_xgbt, test), test$quality)$overall["Accuracy"]
xgbt_acc
```


### torch

```{r}
### Torch / Deep Learning -----

# Change the type from factor to numeric for DNN
train_torch <- 
  train %>% mutate(
    quality = as.numeric(quality) - 1
    )

test_torch <- 
  test %>% mutate(
    quality = as.numeric(quality) - 1
  )

# check the quality 

table(train$quality,train_torch$quality) %>% kable()

# Create {torch} dataset

df_dataset <- dataset(
  
  "wine",
  
  initialize = function(df, response_variable) {
    self$df <- df[,-which(names(df) == response_variable)]
    self$response_variable <- df[[response_variable]]
  },
  
  .getitem = function(index) {
    response <- torch_tensor(self$response_variable[index])
    x <- torch_tensor(as.numeric(self$df[index,]))
    
    list(x = x, y = response)
  },
  
  .length = function() {
    length(self$response_variable)
  }
  
)

# Create the data set train and test

train_torch_ds <- df_dataset(train_torch, "quality")
test_torch_ds <- df_dataset(test_torch, "quality")

# Create the data loader train and test

train_torch_dl <- dataloader(train_torch_ds, batch_size = 32, shuffle = T)
test_torch_dl <- dataloader(test_torch_ds, batch_size = 1, shuffle = F)

# Define a network / fc1 - 3 and dropout

net <- nn_module(
  
  "wine_DNN",
  
  initialize = function() {
    self$fc1 <- nn_linear(11, 66)
    self$fc2 <- nn_linear(66, 44)
    self$fc3 <- nn_linear(44, 1)
    self$dropout <- nn_dropout(0.5)
  },
  
  forward = function(x) {
    x %>% 
      self$fc1() %>%
      nnf_relu() %>%
      self$fc2() %>%
      nnf_relu() %>%
      self$dropout() %>%
      self$fc3() %>%
      nnf_sigmoid()
  }
)

# Use CPU version

model <- net()
model$to(device = "cpu")

# Set the optimizer condition

optimizer <- optim_adam(model$parameters,lr = 0.01)



```


```{r, results='hide'}
# Run a learning iteration

coro::loop(for (epoch in 1:20) {
  
  l <- c()
  
  coro::loop(for (b in enumerate(train_torch_dl)) {
    optimizer$zero_grad()
    output <- model(b[[1]]$to(device = "cpu"))
    loss <- nnf_binary_cross_entropy_with_logits(output, b[[2]]$to(device = "cpu"))
    loss$backward()
    optimizer$step()
    l <- c(l, loss$item())
  })
  
  cat(sprintf("Loss at epoch %d: %3f\n", epoch, mean(l)))
})

# Model prediction

model$eval()

i <- 1
pred_labels <- rep(0, nrow(test_torch))

coro::loop(for (b in enumerate(test_torch_dl)) {
  output <- model(b[[1]]$to(device = "cpu"))
  pred_labels[i] <- round(output$item(), 0)
  i <- i + 1
})


```


```{r}
# Evaluate

table(test=test_torch$quality, pred_labels)

torch_acc <- sum(diag(table(test_torch$quality, pred_labels))) / nrow(test_torch)
torch_acc
```



### Tabnet

```{r}
### Tabnet -----

# splits the data (set vfold to 4 because it takes time)

splits <-  
  vfold_cv(train, v = 4, strata = "quality") %>% 
  with_seed(1, .)

# Create rule "classification"

rule <- tabnet(
  epochs = tune(), 
  penalty = tune(),
  batch_size = tune(), 
  decision_width = tune(), 
  attention_width =tune(),
  num_steps = tune(),
  learn_rate = 0.08,
  momentum = 0.6) %>%
  set_engine("torch", verbose = TRUE) %>% 
  set_mode("classification")

# making a recipe

rec <- recipe(quality ~ ., data = train) %>% 
  step_nzv(all_predictors())

# making a work flow

wf <- workflow() %>% 
  add_model(rule) %>% 
  add_recipe(rec) 

# range of hyper parameter 

range_hypara <- 
  wf %>% 
  parameters() %>% 
  update(
    epochs = epochs(c(50, 70)),
    decision_width = decision_width(range = c(20, 40)),
    attention_width = attention_width(range = c(20, 40)),
    num_steps = num_steps(range = c(4, 8))
  ) %>% 
  finalize(train)

# making a grid

grid <- range_hypara %>% 
  grid_latin_hypercube(size = 1) %>% 
  with_seed(1, .)




```


```{r, results='hide'}
# tuning of hyper parameters (long time)

tune <-  
  wf %>% 
  tune_grid(
    resamples = splits,
    grid = grid,
    control = control_grid(save_pred = TRUE),
    metrics = metric_set(accuracy)
  ) 

# select the best hyper parameters 

good_hypara <-
  tune %>% 
  show_best() %>% 
  dplyr::slice(1)

# update the rule with best parameters

upd_rule <- 
  tabnet(
    epochs = good_hypara %>% pull(epochs), 
    penalty = good_hypara %>% pull(penalty),
    batch_size = good_hypara %>% pull(batch_size), 
    decision_width = good_hypara %>% pull(decision_width), 
    attention_width = good_hypara %>% pull(attention_width),
    num_steps = good_hypara %>% pull(num_steps),
    learn_rate = 0.08,
    momentum = 0.6) %>%
  set_engine("torch", verbose = TRUE) %>%
  set_mode("classification")


# update the work flow with updated rule

upd_wf <- 
  workflow() %>% 
  add_model(upd_rule) %>% 
  add_recipe(rec)

# build the model

model_tn <- 
  upd_wf %>% 
  fit(train) %>% 
  with_seed(1,.)


# Predict 

pred_tabnet <- 
  predict(model_tn,new_data = test, type = "class")



```


```{r}
# Evaluate 

table(test=test$quality, pred= pred_tabnet$.pred_class)

tabnet_acc <- sum(diag(table(test$quality, pred_tabnet$.pred_class))) /
    nrow(test)

tabnet_acc

# Check the importance

fit <- extract_fit_parsnip(model_tn)
p_tabnet <- vip(fit) + ggtitle("Tabnet") 
p_tabnet
```


## Compare the models

As a result of comparing each model using Accuracy, the DART model of XGBoost showed the highest score. Since we have not yet reached the optimal tuning for each model, we cannot judge which model is the best, but XGBoost was able to calculate a high score with a short code for all of them.
In the Importance comparison, all models except Tabnet showed the highest score for Alchol, while Tabnet showed the highest score for free sulfur dioxide. The ability to obtain multiple features in real work is attractive, and in competitions such as Kaggle, we believe it can be used to build ensembles.

```{r,fig.width = 8, fig.height =5}
### Compare the models -----

rbind(logit_acc, rpart_acc, rf_acc, svm_acc, nnet_acc,
      xgbl_acc, xgbd_acc, xgbt_acc, torch_acc, tabnet_acc) %>% kable()


wrap_plots(p_logit, p_rpart, p_nnet, p_rf, p_xgbl, p_xgbd, p_xgbt, p_tabnet)

```


## Additional: Google Colaboratory

In order to perform deep learning using GPU, we tried to calculate with R/torch using Google Colaboratory, where we can build a GPU environment for free. Link of the code and calculation results: **[Google Colab: CYO_colab](https://colab.research.google.com/drive/1LeFefyPnCOq6wgi94-ZZlRjv6uURaRr3?usp=sharing)**

>Note: The library will automatically determine whether the environment is CPU or GPU and install the library, so you need to set the runtime to GPU first and then run the installation.

The number of epochs was set to 20 in this report, but 2000 in the Google Colaboratory calculation. 53 minutes was required in the CPU environment, but 35 minutes in the GPU environment, which reduced the calculation time.

# conclusion

Following the previous MovieLens project, we worked on machine learning about classification using a small data table: Wine Quality dataset, assuming a BtoB business.

We were able to build models not only using the methods from the edx course and the widely used gradient boosting, but also using a library newly incorporated into R in 2020. In search of a better computing environment, we took advantage of the external environment and actually reduced the computation time.

Through this series of initiatives, we were able to learn how to work with data science, which will continue to grow in the future.
By creating many models for the same data set, we were able to learn about the characteristics of each model. On the other hand, we have not yet calculated the optimal values of hyperparameters for each model, so we think this is a future work to be done with better resources such as GPU environment.



# Reference {-}

- Shunsuke1015.github (my previous work: Movie Lens PJ) 
https://github.com/Shunsuke1015/homework-0

- rafalab.github
https://rafalab.github.io/dsbook/large-datasets.html#recommendation-systems

- UCI: Machine Learning Repository
https://archive.ics.uci.edu/ml/index.php

- Pandoc
https://pandoc.org/index.html

- The caret Package
https://topepo.github.io/caret/index.html

- Tidymodels
https://www.tidymodels.org/

- XGBoost.ai
https://xgboost.ai/

- DART: Dropouts meet Multiple Additive Regression Trees (2015)
https://arxiv.org/pdf/1505.01866.pdf

- torch for R
https://torch.mlverse.org/

- Applied deep learning with torch from R
https://mlverse.github.io/torchbook_materials/

- GitHub: mlverse/tabnet
https://github.com/mlverse/tabnet

- TabNet: Attentive Interpretable Tabular Learning (2020)
https://arxiv.org/pdf/1908.07442.pdf

- kaggle: Simple R - xgboost - caret kernel
https://www.kaggle.com/nagsdata/simple-r-xgboost-caret-kernel

- towards data science: How to use R in Google Colab
https://towardsdatascience.com/how-to-use-r-in-google-colab-b6e02d736497

- Wikipedia: Gradient boosting
https://en.wikipedia.org/wiki/Gradient_boosting

- Wikipedia: Deep learning
https://en.wikipedia.org/wiki/Deep_learning


